{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655386a5-aff3-421d-b510-77c8e3f1bb7b",
   "metadata": {},
   "source": [
    "# Answer1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf4f3a-a46a-45ad-874a-3971bbe57088",
   "metadata": {},
   "source": [
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use conditional probability. \n",
    "\n",
    "Let's denote:\n",
    "- A: the event that an employee uses the health insurance plan.\n",
    "- B: the event that an employee is a smoker.\n",
    "\n",
    "The probability of an employee using the health insurance plan is denoted as P(A) = 70% or 0.7, and the probability of an employee being a smoker is denoted as P(B) = 40% or 0.4.\n",
    "\n",
    "The conditional probability of an employee being a smoker given that they use the health insurance plan is denoted as P(B|A), and it is calculated using the formula:\n",
    "\n",
    "[ P(B|A) = \\frac{P(A \\cap B)}{P(A)} \\]\n",
    "\n",
    "In this case, \\( P(A \\cap B) \\) is the probability that an employee both uses the health insurance plan and is a smoker.\n",
    "\n",
    "Given that 40% of the employees who use the plan are smokers, we can say \\( P(A \\cap B) = 0.4 \\).\n",
    "\n",
    "Now, substituting the values into the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88d3d97-8da4-4105-889c-05747fce12cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that an employee is a smoker given that he/she uses the health insurance plan (Naive Bayes): 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_A = 0.7  # Probability of using the health insurance plan\n",
    "P_B = 0.4  # Probability of being a smoker among those who use the plan\n",
    "\n",
    "# Calculate the conditional probability P(B|A) using Naive Bayes theorem\n",
    "P_A_given_B = 1  # Probability of using the health insurance plan given being a smoker\n",
    "\n",
    "# Calculate the result\n",
    "P_B_given_A_naive_bayes = (P_A_given_B * P_B) / P_A\n",
    "\n",
    "print(\"The probability that an employee is a smoker given that he/she uses the health insurance plan (Naive Bayes):\", P_B_given_A_naive_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c538f20-bc48-44fd-9b2c-209c1af34660",
   "metadata": {},
   "source": [
    "# Answer2\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm, and they are commonly used in text classification and other machine learning tasks. The main difference between them lies in the type of data they are designed to handle.\n",
    "\n",
    "1. **Bernoulli Naive Bayes:**\n",
    "   - **Data Type:** Bernoulli Naive Bayes is suitable for binary data, where features are either present or absent. It is commonly used for document classification tasks where the presence or absence of words in a document is considered.\n",
    "   - **Representation:** The input data is often represented as binary vectors, where each feature is represented as 0 or 1 (absence or presence).\n",
    "   - **Example:** In text classification, a document might be represented as a binary vector where each element corresponds to the presence (1) or absence (0) of a specific word in the document.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - **Data Type:** Multinomial Naive Bayes is designed for count-based data, where features represent the frequency of terms or events. It is commonly used in text classification with features like word counts in documents.\n",
    "   - **Representation:** The input data is typically represented as integer counts. For example, in text classification, a document might be represented as a vector of word frequencies.\n",
    "   - **Example:** If the task involves classifying documents based on word frequencies, Multinomial Naive Bayes is a suitable choice.\n",
    "\n",
    "In summary, the choice between Bernoulli and Multinomial Naive Bayes depends on the nature of the features in your dataset. If your features are binary (presence or absence), Bernoulli Naive Bayes is more appropriate. If your features are counts or frequencies, Multinomial Naive Bayes is a better choice. Additionally, there is also a Gaussian Naive Bayes variant, which is suitable for continuous data following a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f056f31-d03a-4ae8-aa1c-274852a482f1",
   "metadata": {},
   "source": [
    "# Answer3\n",
    "In the context of Bernoulli Naive Bayes, missing values are typically treated as the absence of a feature. Since Bernoulli Naive Bayes is designed for binary data where features are either present (1) or absent (0), a missing value is assumed to be equivalent to the absence of the feature.\n",
    "\n",
    "When dealing with missing values in a Bernoulli Naive Bayes model, you generally have two common approaches:\n",
    "\n",
    "1. **Ignore Missing Values:**\n",
    "   - You can simply ignore instances with missing values during training and classification. This means that if a particular feature is missing for a data point, you treat it as if the feature is not present (set it to 0) when calculating probabilities.\n",
    "\n",
    "2. **Impute Missing Values:**\n",
    "   - Another approach is to impute missing values before training the model. You might choose to impute missing values with the most common value (mode) for that feature or use some other imputation method that makes sense for your data. Once the missing values are imputed, you can train the Bernoulli Naive Bayes model as usual.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacac368-d754-4587-89b2-a53d79da7929",
   "metadata": {},
   "source": [
    "# Answer4\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. Gaussian Naive Bayes is a variant of the Naive Bayes algorithm that is suitable for continuous data that follows a Gaussian (normal) distribution. While it is often used for binary and two-class classification problems, it can be extended to handle multi-class classification as well.\n",
    "\n",
    "In the context of multi-class classification, the Gaussian Naive Bayes model makes certain assumptions about the distribution of the features within each class. Specifically, it assumes that the features within each class are normally distributed and estimates the mean and variance for each feature in each class.\n",
    "\n",
    "Here's a general overview of how Gaussian Naive Bayes is adapted for multi-class classification:\n",
    "\n",
    "1. **Parameter Estimation:**\n",
    "   - For each class, the model estimates the mean and variance of each feature based on the training data for that class.\n",
    "\n",
    "2. **Class Prior Probability:**\n",
    "   - The prior probability of each class is calculated based on the proportion of instances belonging to that class in the training data.\n",
    "\n",
    "3. **Classifying New Instances:**\n",
    "   - When classifying a new instance, the model calculates the likelihood of the observed features given each class using the Gaussian probability density function.\n",
    "\n",
    "4. **Decision Rule:**\n",
    "   - The model then applies the Naive Bayes decision rule to assign the instance to the class with the highest posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d01f2-c15f-45ed-8900-a86093244411",
   "metadata": {},
   "source": [
    "# Answer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60c4c98-ee7e-4879-973d-56ef3a65ce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /opt/conda/lib/python3.10/site-packages (0.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac6dbba-d06a-4664-ac7b-c6afd61a291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39247e81-90f2-45d3-9eb4-6dc614d6ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase = fetch_ucirepo(id=94) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28661ed2-8e11-4564-b50d-36094974f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Dependent and Independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0b44a5-d7bb-46e7-b5d0-735b2b274b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spambase.data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd536f7-fab3-4d36-99eb-5950bff13ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0                0.00            0.00  ...                   0.0        0.000   \n",
       "1                0.00            0.94  ...                   0.0        0.000   \n",
       "2                0.64            0.25  ...                   0.0        0.010   \n",
       "3                0.31            0.63  ...                   0.0        0.000   \n",
       "4                0.31            0.63  ...                   0.0        0.000   \n",
       "...               ...             ...  ...                   ...          ...   \n",
       "4596             0.00            0.00  ...                   0.0        0.000   \n",
       "4597             0.00            0.00  ...                   0.0        0.000   \n",
       "4598             0.00            0.00  ...                   0.0        0.102   \n",
       "4599             0.00            0.00  ...                   0.0        0.000   \n",
       "4600             0.00            0.00  ...                   0.0        0.000   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0           0.000          0.0        0.778        0.000        0.000   \n",
       "1           0.132          0.0        0.372        0.180        0.048   \n",
       "2           0.143          0.0        0.276        0.184        0.010   \n",
       "3           0.137          0.0        0.137        0.000        0.000   \n",
       "4           0.135          0.0        0.135        0.000        0.000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4596        0.232          0.0        0.000        0.000        0.000   \n",
       "4597        0.000          0.0        0.353        0.000        0.000   \n",
       "4598        0.718          0.0        0.000        0.000        0.000   \n",
       "4599        0.057          0.0        0.000        0.000        0.000   \n",
       "4600        0.000          0.0        0.125        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  \n",
       "0                          278  \n",
       "1                         1028  \n",
       "2                         2259  \n",
       "3                          191  \n",
       "4                          191  \n",
       "...                        ...  \n",
       "4596                        88  \n",
       "4597                        14  \n",
       "4598                       118  \n",
       "4599                        78  \n",
       "4600                        40  \n",
       "\n",
       "[4601 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5b9d59-dd7e-4c55-aff8-d188ce054e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spambase.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edfa34e4-a321-4262-b62f-9343512c2e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class\n",
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "...     ...\n",
       "4596      0\n",
       "4597      0\n",
       "4598      0\n",
       "4599      0\n",
       "4600      0\n",
       "\n",
       "[4601 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71bbde-658d-4436-a50a-d7e4584274df",
   "metadata": {},
   "source": [
    "## Bernaulli Naive bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aed9924-752d-463a-a28f-44946dcea17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eeef33d-b8c3-48a8-8ba3-7f405b359905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 88.39%\n",
      "Precision: 0.88\n",
      "Recall: 0.88\n",
      "F1 Score: 0.88\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb = BernoulliNB()\n",
    "y_pred_bernoulli = cross_val_predict(bernoulli_nb, X, y, cv=10)\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y, y_pred_bernoulli) * 100))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y, y_pred_bernoulli, average='weighted')))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y, y_pred_bernoulli, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred_bernoulli, average='weighted')))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08836ce1-4a81-4e16-aa07-120322fb973e",
   "metadata": {},
   "source": [
    "# Multinomial Naive bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbab00b2-471b-48af-8f0e-7b387be85a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "Accuracy: 78.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.79\n",
      "F1 Score: 0.79\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb = MultinomialNB()\n",
    "y_pred_multinomial = cross_val_predict(multinomial_nb, X, y, cv=10)\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y, y_pred_multinomial) * 100))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y, y_pred_multinomial, average='weighted')))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y, y_pred_multinomial, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred_multinomial, average='weighted')))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1c59d-c9a2-4ebc-8eba-e36583569dfe",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54877dc3-7771-48b1-936c-dbfcd921d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes:\n",
      "Accuracy: 82.18%\n",
      "Precision: 0.86\n",
      "Recall: 0.82\n",
      "F1 Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb = GaussianNB()\n",
    "y_pred_gaussian = cross_val_predict(gaussian_nb, X, y, cv=10)\n",
    "print(\"Gaussian Naive Bayes:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y, y_pred_gaussian) * 100))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y, y_pred_gaussian, average='weighted')))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y, y_pred_gaussian, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred_gaussian, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c648c-55c2-44ff-aa39-034773883d41",
   "metadata": {},
   "source": [
    "Overall Assessment:\n",
    "\n",
    "In this specific case, the Bernaulli Naive Bayes variant may perform the best because the spam mail dataset consists of Binary features.\n",
    "The choice of the best variant depends on the characteristics of the dataset. Bernoulli is suitable for binary features, Multinomial for discrete features, and Gaussian for continuous features.\n",
    "\n",
    "Limitations of Naive Bayes:\n",
    "\n",
    "1-Assumption of Independence:\n",
    "\n",
    "Naive Bayes assumes that features are conditionally independent given the class. This assumption may not hold in real-world scenarios, leading to suboptimal performance.\n",
    "\n",
    "2-Sensitivity to Feature Distribution:\n",
    "\n",
    "Gaussian Naive Bayes assumes a Gaussian (normal) distribution of features. If the features do not follow this distribution, it might not perform well.\n",
    "\n",
    "3-Zero Probability Issue:\n",
    "\n",
    "In the case of zero-frequency events (features not observed in training), the model assigns zero probability, leading to difficulties in classification.\n",
    "\n",
    "4-Limited Expressiveness:\n",
    "\n",
    "Naive Bayes models have a simple structure and may not capture complex relationships in the data compared to more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c681c36-04ce-48a4-a6a8-a6a8a0fa0f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
